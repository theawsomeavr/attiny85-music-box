<!DOCTYPE html>
<html>
<head><meta charset=utf-8>
<title>Midi to ELM-ChaN wavetable synth</title>
</head>
<body>

<div id="drop_zone">

This is a tool to convert MIDI files into the binary format interpreted by <a href=http://elm-chan.org/works/mxb/report.html>ELM ChaN's wavetable synth for ATtiny45</a>. Replace the contents of <code>melody.asm</code> with the generated output.<br><br>



<div id="output">Drag and drop a midi file here to convert </div>
<div id="output2"></div>

<div style="overflow:auto; overflow-x:scroll;">
<canvas id="c" style="border: 1px solid black;" width=5000 height=384></canvas>
</div>

<label>Hscale (for display only, no effect on output):<input type=range oninput='Hscale=this.value*this.value/100000; window.redraw&&redraw()' autocomplete=off value=175 min=1 max=500></label> <br>
<label>Transpose:<input type=range oninput='transpose = this.value-128; window.redraw&&redraw(); ' autocomplete=off value=128 min=1 max=255 style='width:1000px'></label><br>







<!--<br><br>
<a href=# onclick='if(window.redo) window.redo(); return false;'>redo</a> 
<a href=# onclick='if(window.redraw) window.redraw(); return false;'>redraw</a>
<br><br>-->

<br>Size limit: 
<label><input onchange='window.redraw()' type=radio name=sizesel id=t45 checked>Attiny45</label>
<label><input onchange='window.redraw()' type=radio name=sizesel id=t85>Attiny85</label>
<br>
(For ATtiny85, remember to change line 303 of <code>mg.asm</code> to <code>.org 3584</code> in order to move the wavetables to the end)
<br>
<br>
<a href=# onclick='exportAsm();return false;'>Generate output</a>
<br>
<textarea id=output3 style='width:500px;height:200px'></textarea>

<script>
window.redraw=function(){};

/* Wrapper for accessing strings through sequential reads */
function Stream(str) {
	var position = 0;
	
	function read(length) {
		var result = str.substr(position, length);
		position += length;
		return result;
	}
	
	/* read a big-endian 32-bit integer */
	function readInt32() {
		var result = (
			(str.charCodeAt(position) << 24)
			+ (str.charCodeAt(position + 1) << 16)
			+ (str.charCodeAt(position + 2) << 8)
			+ str.charCodeAt(position + 3));
		position += 4;
		return result;
	}

	/* read a big-endian 16-bit integer */
	function readInt16() {
		var result = (
			(str.charCodeAt(position) << 8)
			+ str.charCodeAt(position + 1));
		position += 2;
		return result;
	}
	
	/* read an 8-bit integer */
	function readInt8() {
		var result = str.charCodeAt(position);
		position += 1;
		return result;
	}
	
	function eof() {
		return position >= str.length;
	}
	
	/* read a MIDI-style variable-length integer
		(big-endian value in groups of 7 bits,
		with top bit set to signify that another byte follows)
	*/
	function readVarInt() {
		var result = 0;
		while (true) {
			var b = readInt8();
			if (b & 0x80) {
				result += (b & 0x7f);
				result <<= 7;
			} else {
				/* b is the last byte */
				return result + b;
			}
		}
	}
	
	return {
		'eof': eof,
		'read': read,
		'readInt32': readInt32,
		'readInt16': readInt16,
		'readInt8': readInt8,
		'readVarInt': readVarInt
	}
}


/*
class to parse the .mid file format
(depends on stream.js)
*/
function MidiFile(data) {
	function readChunk(stream) {
		var id = stream.read(4);
		var length = stream.readInt32();
		return {
			'id': id,
			'length': length,
			'data': stream.read(length)
		};
	}
	
	var lastEventTypeByte;
	
	function readEvent(stream) {
		var event = {};
		event.deltaTime = stream.readVarInt();
		var eventTypeByte = stream.readInt8();
		if ((eventTypeByte & 0xf0) == 0xf0) {
			/* system / meta event */
			if (eventTypeByte == 0xff) {
				/* meta event */
				event.type = 'meta';
				var subtypeByte = stream.readInt8();
				var length = stream.readVarInt();
				switch(subtypeByte) {
					case 0x00:
						event.subtype = 'sequenceNumber';
						if (length != 2) throw "Expected length for sequenceNumber event is 2, got " + length;
						event.number = stream.readInt16();
						return event;
					case 0x01:
						event.subtype = 'text';
						event.text = stream.read(length);
						return event;
					case 0x02:
						event.subtype = 'copyrightNotice';
						event.text = stream.read(length);
						return event;
					case 0x03:
						event.subtype = 'trackName';
						event.text = stream.read(length);
						return event;
					case 0x04:
						event.subtype = 'instrumentName';
						event.text = stream.read(length);
						return event;
					case 0x05:
						event.subtype = 'lyrics';
						event.text = stream.read(length);
						return event;
					case 0x06:
						event.subtype = 'marker';
						event.text = stream.read(length);
						return event;
					case 0x07:
						event.subtype = 'cuePoint';
						event.text = stream.read(length);
						return event;
					case 0x20:
						event.subtype = 'midiChannelPrefix';
						if (length != 1) throw "Expected length for midiChannelPrefix event is 1, got " + length;
						event.channel = stream.readInt8();
						return event;
					case 0x2f:
						event.subtype = 'endOfTrack';
						if (length != 0) throw "Expected length for endOfTrack event is 0, got " + length;
						return event;
					case 0x51:
						event.subtype = 'setTempo';
						if (length != 3) throw "Expected length for setTempo event is 3, got " + length;
						event.microsecondsPerBeat = (
							(stream.readInt8() << 16)
							+ (stream.readInt8() << 8)
							+ stream.readInt8()
						)
						return event;
					case 0x54:
						event.subtype = 'smpteOffset';
						if (length != 5) throw "Expected length for smpteOffset event is 5, got " + length;
						var hourByte = stream.readInt8();
						event.frameRate = {
							0x00: 24, 0x20: 25, 0x40: 29, 0x60: 30
						}[hourByte & 0x60];
						event.hour = hourByte & 0x1f;
						event.min = stream.readInt8();
						event.sec = stream.readInt8();
						event.frame = stream.readInt8();
						event.subframe = stream.readInt8();
						return event;
					case 0x58:
						event.subtype = 'timeSignature';
						if (length != 4) throw "Expected length for timeSignature event is 4, got " + length;
						event.numerator = stream.readInt8();
						event.denominator = Math.pow(2, stream.readInt8());
						event.metronome = stream.readInt8();
						event.thirtyseconds = stream.readInt8();
						return event;
					case 0x59:
						event.subtype = 'keySignature';
						if (length != 2) throw "Expected length for keySignature event is 2, got " + length;
						event.key = stream.readInt8();
						event.scale = stream.readInt8();
						return event;
					case 0x7f:
						event.subtype = 'sequencerSpecific';
						event.data = stream.read(length);
						return event;
					default:
						// console.log("Unrecognised meta event subtype: " + subtypeByte);
						event.subtype = 'unknown'
						event.data = stream.read(length);
						return event;
				}
				event.data = stream.read(length);
				return event;
			} else if (eventTypeByte == 0xf0) {
				event.type = 'sysEx';
				var length = stream.readVarInt();
				event.data = stream.read(length);
				return event;
			} else if (eventTypeByte == 0xf7) {
				event.type = 'dividedSysEx';
				var length = stream.readVarInt();
				event.data = stream.read(length);
				return event;
			} else {
				throw "Unrecognised MIDI event type byte: " + eventTypeByte;
			}
		} else {
			/* channel event */
			var param1;
			if ((eventTypeByte & 0x80) == 0) {
				/* running status - reuse lastEventTypeByte as the event type.
					eventTypeByte is actually the first parameter
				*/
				param1 = eventTypeByte;
				eventTypeByte = lastEventTypeByte;
			} else {
				param1 = stream.readInt8();
				lastEventTypeByte = eventTypeByte;
			}
			var eventType = eventTypeByte >> 4;
			event.channel = eventTypeByte & 0x0f;
			event.type = 'channel';
			switch (eventType) {
				case 0x08:
					event.subtype = 'noteOff';
					event.noteNumber = param1;
					event.velocity = stream.readInt8();
					return event;
				case 0x09:
					event.noteNumber = param1;
					event.velocity = stream.readInt8();
					if (event.velocity == 0) {
						event.subtype = 'noteOff';
					} else {
						event.subtype = 'noteOn';
					}
					return event;
				case 0x0a:
					event.subtype = 'noteAftertouch';
					event.noteNumber = param1;
					event.amount = stream.readInt8();
					return event;
				case 0x0b:
					event.subtype = 'controller';
					event.controllerType = param1;
					event.value = stream.readInt8();
					return event;
				case 0x0c:
					event.subtype = 'programChange';
					event.programNumber = param1;
					return event;
				case 0x0d:
					event.subtype = 'channelAftertouch';
					event.amount = param1;
					return event;
				case 0x0e:
					event.subtype = 'pitchBend';
					event.value = param1 + (stream.readInt8() << 7);
					return event;
				default:
					throw "Unrecognised MIDI event type: " + eventType
			}
		}
	}
	
	stream = Stream(data);
	var headerChunk = readChunk(stream);
	if (headerChunk.id != 'MThd' || headerChunk.length != 6) {
		throw "Bad .mid file - header not found";
	}
	var headerStream = Stream(headerChunk.data);
	var formatType = headerStream.readInt16();
	var trackCount = headerStream.readInt16();
	var timeDivision = headerStream.readInt16();
	
	if (timeDivision & 0x8000) {
		throw "Expressing time division in SMTPE frames is not supported yet"
	} else {
		ticksPerBeat = timeDivision;
	}
	
	var header = {
		'formatType': formatType,
		'trackCount': trackCount,
		'ticksPerBeat': ticksPerBeat
	}
	var tracks = [];
	for (var i = 0; i < header.trackCount; i++) {
		tracks[i] = [];
		var trackChunk = readChunk(stream);
		if (trackChunk.id != 'MTrk') {
			throw "Unexpected chunk - expected MTrk, got "+ trackChunk.id;
		}
		var trackStream = Stream(trackChunk.data);
		while (!trackStream.eof()) {
			var event = readEvent(trackStream);
			tracks[i].push(event);
			//console.log(event);
		}
	}
	
	return {
		'header': header,
		'tracks': tracks
	}
}


function Replayer(midiFile, synth, onFinish) {
	var trackStates = [];
	var beatsPerMinute = 120;
	var ticksPerBeat = midiFile.header.ticksPerBeat;
	var channelCount = 16;
	
	for (var i = 0; i < midiFile.tracks.length; i++) {
		trackStates[i] = {
			'nextEventIndex': 0,
			'ticksToNextEvent': (
				midiFile.tracks[i].length ?
					midiFile.tracks[i][0].deltaTime :
					null
			)
		};
	}
	
	function Channel(num) {
		
		var generatorsByNote = {};
		var currentProgram = PianoProgram;
		var tempLastNote=1
		
		function noteOn(note, velocity) {
			if (num!=9) {
			  NoteOnStack.push([FrameNumber,note])
			}
		
			if (generatorsByNote[note] && !generatorsByNote[note].released) {
				generatorsByNote[note].noteOff(); 
			}
    
			generator = currentProgram.createNote(note, velocity);
			synth.addGenerator(generator);
			generatorsByNote[note] = generator;
		}
		function noteOff(note, velocity) {
      
      generatorsByNote[note].noteOff(velocity);
      
		}
		function setProgram(programNumber) {

      currentProgram = PROGRAMS[programNumber] || PianoProgram;
		}
		
		return {
			'noteOn': noteOn,
			'noteOff': noteOff,
			'setProgram': setProgram
		}
	}
	
	var channels = [];
	for (var i = 0; i < channelCount; i++) {
		channels[i] = Channel(i);
	}
  
  channels[9].setProgram(128);  //Set channel 10 to drums
  
	var nextEventInfo;
	var samplesToNextEvent = 0;
	
	function getNextEvent() {
		var ticksToNextEvent = null;
		var nextEventTrack = null;
		var nextEventIndex = null;
		
		for (var i = 0; i < trackStates.length; i++) {
			if (
				trackStates[i].ticksToNextEvent != null
				&& (ticksToNextEvent == null || trackStates[i].ticksToNextEvent < ticksToNextEvent)
			) {
				ticksToNextEvent = trackStates[i].ticksToNextEvent;
				nextEventTrack = i;
				nextEventIndex = trackStates[i].nextEventIndex;
			}
		}
		if (nextEventTrack != null) {
			/* consume event from that track */
			var nextEvent = midiFile.tracks[nextEventTrack][nextEventIndex];
			if (midiFile.tracks[nextEventTrack][nextEventIndex + 1]) {
				trackStates[nextEventTrack].ticksToNextEvent += midiFile.tracks[nextEventTrack][nextEventIndex + 1].deltaTime;
			} else {
				trackStates[nextEventTrack].ticksToNextEvent = null;
			}
			trackStates[nextEventTrack].nextEventIndex += 1;
			/* advance timings on all tracks by ticksToNextEvent */
			for (var i = 0; i < trackStates.length; i++) {
				if (trackStates[i].ticksToNextEvent != null) {
					trackStates[i].ticksToNextEvent -= ticksToNextEvent
				}
			}
			nextEventInfo = {
				'ticksToEvent': ticksToNextEvent,
				'event': nextEvent,
				'track': nextEventTrack
			}
			var beatsToNextEvent = ticksToNextEvent / ticksPerBeat;
			var secondsToNextEvent = beatsToNextEvent / (beatsPerMinute / 60);
			samplesToNextEvent += secondsToNextEvent * synth.sampleRate;
		} else {
			nextEventInfo = null;
			samplesToNextEvent = null;
			self.finished = true;
      onFinish();
		}
	}
	
	getNextEvent();
	
	function generate(samples) {
		var data = new Array(samples*2);
		
		
		var samplesRemaining = samples;
		var dataOffset = 0;
		
		while (true) {
			if (samplesToNextEvent != null && samplesToNextEvent <= samplesRemaining) {
				/* generate samplesToNextEvent samples, process event and repeat */
				var samplesToGenerate = Math.ceil(samplesToNextEvent);
				if (samplesToGenerate > 0) {
					synth.generateIntoBuffer(samplesToGenerate, data, dataOffset);
					dataOffset += samplesToGenerate * 2;
					samplesRemaining -= samplesToGenerate;
					samplesToNextEvent -= samplesToGenerate;
				}
				
				handleEvent();
				getNextEvent();
			} else {
				/* generate samples to end of buffer */
				if (samplesRemaining > 0) {
					synth.generateIntoBuffer(samplesRemaining, data, dataOffset);
					samplesToNextEvent -= samplesRemaining;
				}
				break;
			}
		}
		return data;
	}
	
	function handleEvent() {
		var event = nextEventInfo.event;
		switch (event.type) {
			case 'meta':
				switch (event.subtype) {
					case 'setTempo':
						beatsPerMinute = 60000000 / event.microsecondsPerBeat
				}
				break;
			case 'channel':
				//if (event.channel!=9)  //Filter out drum track (channel 10)
        switch (event.subtype) {
					case 'noteOn':
						channels[event.channel].noteOn(event.noteNumber, event.velocity);
						break;
					case 'noteOff':
						channels[event.channel].noteOff(event.noteNumber, event.velocity);
						break;
					case 'programChange':
            if (event.channel!=9) //Channel 10 is always drum track
						  channels[event.channel].setProgram(event.programNumber);
						break;
				}
				break;
		}
	}
	
	function replay(audio) {
		console.log('replay');
		audio.write(generate(44100));
		setTimeout(function() {replay(audio)}, 10);
	}
	
	var self = {
		'replay': replay,
		'generate': generate,
		'finished': false
	}
	return self;
}





function ADSRGenerator() {
	var self = {'alive': true}

	self.noteOff = function() {self.alive = false;}
	self.generate = function() {}
	
	return self;
}




PianoProgram = {
	'createNote': ADSRGenerator
}




PROGRAMS = {
};

function Synth(sampleRate) {
	
	var generators = [];
	
	function addGenerator(generator) {
		generators.push(generator);
	}
	
	function generate(samples) {
		var data = new Array(samples*2);
		generateIntoBuffer(samples, data, 0);
		return data;
	}
	
	function generateIntoBuffer(samplesToGenerate, buffer, offset) {
		for (var i = offset; i < offset + samplesToGenerate * 2; i++) {
			buffer[i] = 0;
		}
		for (var i = generators.length - 1; i >= 0; i--) {
			generators[i].generate(buffer, offset, samplesToGenerate);
			if (!generators[i].alive) generators.splice(i, 1);
		}
	}
	
	return {
		'sampleRate': sampleRate,
		'addGenerator': addGenerator,
		'generate': generate,
		'generateIntoBuffer': generateIntoBuffer
	}
}





c=document.getElementById('c');
ctx=c.getContext('2d');
Hscale=0.3
DPI=1/10; //mm per pixel
transpose=0;
wrap=0;

maxLength = 2257;


/*



.equ	A2 = 0		;220Hz
.equ	B2 = 1
.equ	H2 = 2
.equ	C2 = 3
.equ	Cis2 = 4
.equ	D2 = 5
.equ	Dis2 = 6
.equ	E2 = 7
.equ	F2 = 8
.equ	Fis2 = 9
.equ	G2 = 10
.equ	Gis2 = 11
.equ	A3 = 12		;440Hz
.equ	B3 = 13
.equ	H3 = 14
.equ	C3 = 15
.equ	Cis3 = 16
.equ	D3 = 17
.equ	Dis3 = 18
.equ	E3 = 19
.equ	F3 = 20
.equ	Fis3 = 21
.equ	G3 = 22
.equ	Gis3 = 23
.equ	A4 = 24		;880Hz
.equ	B4 = 25
.equ	H4 = 26
.equ	C4 = 27
.equ	Cis4 = 28
.equ	D4 = 29
.equ	Dis4 = 30
.equ	E4 = 31
.equ	F4 = 32
.equ	Fis4 = 33
.equ	G4 = 34
.equ	Gis4 = 35
.equ	A5 = 36		;1760Hz
.equ	B5 = 37
.equ	H5 = 38
.equ	C5 = 39
.equ	Cis5 = 40
.equ	D5 = 41
.equ	Dis5 = 42
.equ	E5 = 43
.equ	F5 = 44
.equ	Fis5 = 45
.equ	G5 = 46
.equ	Gis5 = 47
.equ	A6 = 48		;3520Hz
.equ	B6 = 49
.equ	H6 = 50
.equ	C6 = 51
.equ	Cis6 = 52
.equ	D6 = 53
.equ	Dis6 = 54
.equ	E6 = 55

    MIDI 69 is A3.
    ELM mel numbers start at A2 -> MIDI 57.
*/

noteLookup = [ 
  57,
  58,
  59,
  60,
  61,
  62,
  63,
  64,
  65,
  66,
  67,
  68,
  69,
  70,
  71,
  72,
  73,
  74,
  75,
  76,
  77,
  78,
  79,
  80,
  81,
  82,
  83,
  84,
  85,
  86,
  87,
  88,
  89,
  90,
  91,
  92,
  93,
  94,
  95,
  96,
  97,
  98,
  99,
  100,
  101,
  102,
  103,
  104,
  105,
  106,
  107,
  108,
  109,
  110,
  111
]



NoteOnStack=[];
parsedNoteStack=[];
function AudioPlayer(generator) {


  sampleRate = 44100; 

  NoteOnStack=[];
  FrameNumber=0;
  ctx.clearRect(0,0,5000,384);

	var requestStop = false;

 	prevPair="";
	pairCount=1;   
	notePair=""

  var TempGen=function (e) {

    for (var i=1000;i--&&!generator.finished;){

      
      //11000 ticks is 84 seconds -> 131 ticks per second
      //44100 samples per second -> 337 samples per tick
      
      generator.generate(337);
      FrameNumber++

  
    }
    for (var i=0;i<NoteOnStack.length;i++)
      ctx.fillRect(NoteOnStack[i][0]*Hscale, 384-NoteOnStack[i][1]*3, 3,3);
    
    
    document.getElementById("output2").innerHTML=NoteOnStack.length
    if (!generator.finished && !requestStop) window.setTimeout(TempGen, 1);
    else {
      

      (window.redraw=function(){
        maxLength = document.getElementById('t85').checked ? 2257+4096: 2257;
        
        ctx.clearRect(0,0,5000,384);

        ctx.fillStyle='#ddd';
        for (var i=0;i<noteLookup.length;i++){
          ctx.fillRect(0,384-noteLookup[i]*3,5000,3);
        }

        
        parsedNoteStack=[];
        curTick=-1;

        
        function pushNote(f,n){
        
          if (f>=65535) return false;
          
        // total length < 2258 (attiny45) or 2258+4096 (attiny85)
          if (parsedNoteStack.length >=maxLength) return false;
        
          if (curTick==f){
            parsedNoteStack.push(n-57);
          } else {
            if (parsedNoteStack.length) parsedNoteStack[parsedNoteStack.length-1] +=128;
            parsedNoteStack.push(f &0xFF);
            parsedNoteStack.push(f >>8);
            parsedNoteStack.push(n-57);
          }
          curTick=f;
          return true;
        }

        for (var i=0;i<NoteOnStack.length;i++) {
          var n= NoteOnStack[i][1] + transpose;
          if (noteLookup.indexOf(n)==-1) {
            ctx.fillStyle= 'red';
            if (wrap) {
              var d=n<66 ? 12:-12;
              while (noteLookup.indexOf(n)==-1) n+=d;
              pushNote(NoteOnStack[i][0],n);
            }
          } else {
            if (pushNote(NoteOnStack[i][0],n)) ctx.fillStyle= 'black';
            else ctx.fillStyle= 'red';
          }

          ctx.fillRect(NoteOnStack[i][0]*Hscale, 384-n*3, 3,3);
          
        }
        parsedNoteStack.push(255);
        

      })();
  
      
    }
  }
  TempGen();
  
  return {
    'stop': function() {
      requestStop = true;

    },
    'type': ''
  }

} 


function exportAsm(){
  var out="";
  for (var i=0;i<parsedNoteStack.length;i++) {
    if (i%16==0) out+="\n.db ";
    out+=parsedNoteStack[i];
    if ((i+1)%16!=0 && i+1!=parsedNoteStack.length) out+=',';
  }
  document.getElementById('output3').textContent=out;


}










function handleFileSelect(evt) {
  evt.stopPropagation();
  evt.preventDefault();

  files = evt.dataTransfer.files; 
  // files is a FileList of File objects.

  if (files[0].name.indexOf(".mid")==-1) return;
  
  remove_button=function() {  document.getElementById("output").innerHTML="Drag and drop a midi file here to convert "; }  
  document.getElementById("output").innerHTML=files[0].name+" <button onclick='audio.stop();remove_button();'>Stop</button>";
    
  var reader = new FileReader();
  reader.onload = (function(theFile) {
    return function(e) {
      if (typeof audio !=="undefined") audio.stop();
      midiFile = MidiFile(e.target.result);
			synth = Synth(44100);
			replayer = Replayer(midiFile, synth, remove_button );
//			if (document.getElementById("toFile").checked) audio = AudioPlayer(replayer, files[0].name.replace(".mid",".wav")); else
      audio = AudioPlayer(replayer);
    };
  })(files[0]);
    
  reader.readAsBinaryString(files[0]);

  window.redo=function(){reader.readAsBinaryString(files[0]);}
}

function handleDragOver(evt) {
  evt.stopPropagation();
  evt.preventDefault();
  evt.dataTransfer.dropEffect = 'copy'; // Explicitly show this is a copy.
}


var dropZone = document.body;
dropZone.addEventListener('dragover', handleDragOver, false);
dropZone.addEventListener('drop', handleFileSelect, false);









</script>


</div>

</body>
</html>